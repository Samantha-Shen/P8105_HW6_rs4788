---
title: "HW6"
output: github_document
---


```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(forcats)
library(purrr)
library(modelr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

### Create variable & tidy data:
```{r}
homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = disposition != "Open/No arrest",
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  )
```


### Try to  fit a logistic regression for Baltimore:
```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  mutate(
    victim_sex  = fct_relevel(victim_sex, "Female"),
    victim_race = fct_relevel(victim_race, "White")
  )

baltimore_fit = 
  baltimore_df %>% 
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data   = .,
    family = binomial()
  )

baltimore_or =
  baltimore_fit %>% 
  tidy(conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_sexMale") %>% 
  select(term, estimate, conf.low, conf.high)

baltimore_or
```


### Apply the model to other cities:
```{r}
model_df = 
  homicide_df %>% 
  mutate(
    victim_sex  = fct_relevel(victim_sex, "Female"),
    victim_race = fct_relevel(victim_race, "White")
  )

city_or_df = 
  model_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    fit = map(
      data,
      ~ glm(
          resolved ~ victim_age + victim_sex + victim_race,
          data   = .x,
          family = binomial()
        )
    ),
    tidy_res = map(
      fit,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) %>% 
  select(city_state, tidy_res) %>% 
  unnest(tidy_res) %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  )

city_or_df %>% head()
```


### Creat a plot:
```{r, fig.height = 14, fig.width = 7, out.width = "100%"}
city_or_plot = 
  city_or_df %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>% 
  ggplot(aes(x = estimate, y = city_state)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  labs(
    title = "Odds Ratios for Homicide Resolution by City",
    x = "Adjusted odds ratio (male vs female)",
    y = NULL
  ) +
  theme(
    axis.text.y = element_text(size = 6),
  )

city_or_plot
```

Across all cities, only Fresno, Minneapolis, and Stockton had OR estimates exceeding 1. The point estimates for all other cities were below 1, and over half of the cities had confidence intervals entirely on the left side of 1. This indicates that, controlling for age and race, homicides with male victims generally tend to be less likely to be resolved than homicides with female victims.


## Problem 2
```{r}
library(p8105.datasets)
data("weather_df")
```

### Estimates of two quantities:
```{r}
weather_df_clean = 
  weather_df %>% 
  drop_na(tmax, tmin, prcp)

weather_fit = 
  weather_df_clean %>% 
  lm(tmax ~ tmin + prcp, data = .)

weather_fit %>% 
  glance() %>% 
  select(r.squared)

beta_ratio =
  weather_fit %>% 
  tidy() %>% 
  filter(term %in% c("tmin", "prcp")) %>% 
  select(term, estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  mutate(beta_ratio = tmin / prcp) %>% 
  pull(beta_ratio)

beta_ratio

set.seed(8105)

boot_results = 
  weather_df_clean %>% 
  modelr::bootstrap(n = 5000) %>%
  mutate(
    df   = map(strap, as_tibble),
    fit  = map(df, ~ lm(tmax ~ tmin + prcp, data = .x)),
    gln  = map(fit, glance),
    tdy  = map(fit, tidy),
    r_squared = map_dbl(gln, "r.squared"),
    beta_ratio = map_dbl(
      tdy,
      ~ .x %>% 
        filter(term %in% c("tmin", "prcp")) %>% 
        select(term, estimate) %>% 
        pivot_wider(names_from = term, values_from = estimate) %>% 
        summarise(beta_ratio = tmin / prcp) %>% 
        pull(beta_ratio)
    )
  ) %>% 
  select(.id, r_squared, beta_ratio)
```

### Plot distribution:
```{r}
boot_long = 
  boot_results %>% 
  pivot_longer(
    cols = c(r_squared, beta_ratio),
    names_to = "parameter",
    values_to = "estimate"
  ) %>% 
  mutate(
    parameter = recode(
      parameter,
      r_squared  = "r^2",
      beta_ratio = "hat(beta)[1] / hat(beta)[2]"
    ),
    parameter = factor(
      parameter,
      levels = c("r^2", "hat(beta)[1] / hat(beta)[2]")
    )
  )

boot_long %>% 
  ggplot(aes(x = estimate)) +
  geom_density() +
  facet_wrap(~ parameter, 
             scales = "free",
             labeller = label_parsed) +
  labs(
    title = expression(
      paste("Bootstrap distributions of ", r^2, " and ", hat(beta)[1] / hat(beta)[2])
    ),
    x = "Bootstrap estimates",
    y = "Density"
  )
```

The bootstrap distribution of $r^2$ is unimodal and approximately symmetric, concentrated in a narrow range around 0.94. This suggests that the proportion of variation in $tmax$ explained by the model is fairly stable across resamples and is estimated with high precision. In contrast, the bootstrap distribution of $\hat{\beta}_1 / \hat{\beta}_2$ is much more spread out and somewhat skewed toward large negative values. This indicates substantial uncertainty in the ratio of the coefficients for $tmin$ and $prcp$, meaning that the relative importance of these two predictors is estimated much less precisely than the overall model fit.


### 95% CI interval:
```{r}
boot_ci = 
  boot_results %>% 
  summarise(
    r2_low     = quantile(r_squared, 0.025),
    r2_high    = quantile(r_squared, 0.975),
    ratio_low  = quantile(beta_ratio, 0.025),
    ratio_high = quantile(beta_ratio, 0.975)
  )

boot_ci
```

Based on the 5000 bootstrap estimates, the 95% confidence interval for $r^2$ is 
[`r round(boot_ci$r2_low, 3)`, `r round(boot_ci$r2_high, 3)`], 
and the 95% confidence interval for $\hat{\beta}_1 / \hat{\beta}_2$ is 
[`r round(boot_ci$ratio_low, 0)`, `r round(boot_ci$ratio_high, 0)`].